{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 1 | Mask Recognition: Classify people wearing masks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. INITIALIZATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.1 IMPORTS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from xml.dom import minidom\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "cv2                 4.5.3\n",
       "matplotlib          3.4.3\n",
       "numpy               1.21.3\n",
       "pandas              1.3.4\n",
       "session_info        1.0.0\n",
       "sklearn             1.0\n",
       "torch               1.10.0+cu102\n",
       "torchvision         0.11.1+cu102\n",
       "tqdm                4.62.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         8.4.0\n",
       "apport_python_hook          NA\n",
       "astunparse                  1.6.3\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "cffi                        1.14.6\n",
       "colorama                    0.4.3\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.7.3\n",
       "debugpy                     1.4.1\n",
       "decorator                   5.0.9\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "google                      NA\n",
       "ipykernel                   6.3.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.0\n",
       "joblib                      1.0.1\n",
       "kiwisolver                  1.3.2\n",
       "matplotlib_inline           NA\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "parso                       0.8.2\n",
       "pexpect                     4.6.0\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "ptyprocess                  0.7.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.4.1\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   2.4.7\n",
       "pytz                        2019.3\n",
       "scipy                       1.7.1\n",
       "sitecustomize               NA\n",
       "six                         1.15.0\n",
       "storemagic                  NA\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.0\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "zmq                         22.2.1\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.29.0\n",
       "jupyter_client      7.0.2\n",
       "jupyter_core        4.7.1\n",
       "notebook            6.4.3\n",
       "-----\n",
       "Python 3.8.10 (default, Sep 28 2021, 16:10:42) [GCC 9.3.0]\n",
       "Linux-5.11.0-40-generic-x86_64-with-glibc2.29\n",
       "-----\n",
       "Session information updated at 2021-11-15 16:04\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fill the `requirement.txt` file we use the following line of code:\n",
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.2. DATA LOADING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/FaceMaskDetection/\"\n",
    "anno_dir = root_dir + \"annotations/\"\n",
    "imgs_dir = root_dir + \"images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(anno_dir):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arg:\n",
    "    - anno_dir (str):   the directory with the .xml annotations files\n",
    "    \n",
    "    out:\n",
    "    - df (dataframe):   a dataframe matching an image id and a bounding box id to the size of\n",
    "                        the image, the position of the bounding box and its annotation:\n",
    "                        \"without mask\" or \"mask_weared_incorrect\" => 0 | \"with mask\" => 1  \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    files = os.listdir(anno_dir)\n",
    "    files.sort()\n",
    "    \n",
    "    # if the dataframe doesn't exist been created yet\n",
    "    if \"annotations.csv\" not in files:\n",
    "\n",
    "        data = []\n",
    "        mask_label = {\"without_mask\": 0, \"mask_weared_incorrect\": 1, \"with_mask\": 1}\n",
    "\n",
    "        for file in files:\n",
    "        \n",
    "            ann = minidom.parse(anno_dir+file)\n",
    "            img_id = int(ann.getElementsByTagName(\"filename\")[0].firstChild.data[12:-4])\n",
    "            img_height = int(ann.getElementsByTagName(\"height\")[0].firstChild.data)\n",
    "            img_width = int(ann.getElementsByTagName(\"width\")[0].firstChild.data)\n",
    "        \n",
    "            for i,object in enumerate(ann.getElementsByTagName(\"object\")):\n",
    "\n",
    "                box_id = i\n",
    "                label = mask_label[object.getElementsByTagName(\"name\")[0].firstChild.data]\n",
    "                xmin = object.getElementsByTagName(\"xmin\")[0].firstChild.data\n",
    "                xmax = object.getElementsByTagName(\"xmax\")[0].firstChild.data\n",
    "                ymin = object.getElementsByTagName(\"ymin\")[0].firstChild.data\n",
    "                ymax = object.getElementsByTagName(\"ymax\")[0].firstChild.data\n",
    "\n",
    "                data.append((img_id, img_height, img_width, box_id, label, xmin, xmax, ymin, ymax))\n",
    "        \n",
    "        columns = [\"img_id\", \"img_height\", \"img_width\", \"box_id\", \"label\", \"xmin\", \"xmax\", \"ymin\", \"ymax\"]\n",
    "        pd.DataFrame(data=data, columns=columns, index=None).to_csv(anno_dir+\"annotations.csv\", index=None)\n",
    "        \n",
    "    return pd.read_csv(anno_dir+\"/annotations.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>box_id</th>\n",
       "      <th>label</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>109</td>\n",
       "      <td>105</td>\n",
       "      <td>142</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>226</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>360</td>\n",
       "      <td>90</td>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>354</td>\n",
       "      <td>34</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>261</td>\n",
       "      <td>38</td>\n",
       "      <td>73</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>98</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>263</td>\n",
       "      <td>287</td>\n",
       "      <td>62</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>98</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>377</td>\n",
       "      <td>80</td>\n",
       "      <td>106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>99</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>273</td>\n",
       "      <td>54</td>\n",
       "      <td>162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>99</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>176</td>\n",
       "      <td>87</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>99</td>\n",
       "      <td>267</td>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>355</td>\n",
       "      <td>99</td>\n",
       "      <td>233</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4072 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_id  img_height  img_width  box_id  label  xmin  xmax  ymin  ymax  \\\n",
       "0          0         366        512       0      0    79   109   105   142   \n",
       "1          0         366        512       1      1   185   226   100   144   \n",
       "2          0         366        512       2      0   325   360    90   141   \n",
       "3          1         156        400       0      1   321   354    34    69   \n",
       "4          1         156        400       1      1   224   261    38    73   \n",
       "...      ...         ...        ...     ...    ...   ...   ...   ...   ...   \n",
       "4067      98         267        400       2      1   263   287    62    85   \n",
       "4068      98         267        400       3      1   344   377    80   106   \n",
       "4069      99         267        400       0      1   181   273    54   162   \n",
       "4070      99         267        400       1      1    99   176    87   165   \n",
       "4071      99         267        400       2      1   289   355    99   233   \n",
       "\n",
       "      train  \n",
       "0      True  \n",
       "1      True  \n",
       "2      True  \n",
       "3      True  \n",
       "4      True  \n",
       "...     ...  \n",
       "4067   True  \n",
       "4068   True  \n",
       "4069   True  \n",
       "4070   True  \n",
       "4071   True  \n",
       "\n",
       "[4072 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations = get_annotations(anno_dir)\n",
    "display(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceMaskDataset(Dataset):\n",
    "\n",
    "    def __init__(self, annotations, imgs_dir):\n",
    "        self.annotations = annotations\n",
    "        self.img_dir = imgs_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = plt.imread(self.img_dir+\"maksssksksss{}.png\".format(int(self.annotations.iloc[idx][\"img_id\"])))[:,:,:3]\n",
    "        xmin = self.annotations.iloc[idx][\"xmin\"]\n",
    "        xmax = self.annotations.iloc[idx][\"xmax\"]\n",
    "        ymin = self.annotations.iloc[idx][\"ymin\"]\n",
    "        ymax = self.annotations.iloc[idx][\"ymax\"]\n",
    "        img = transforms.Resize((64,64))(torch.Tensor(img[ymin:ymax,xmin:xmax]).permute(2,0,1))\n",
    "        label = torch.Tensor([int(self.annotations.iloc[idx][\"label\"])])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% of the whole dataset is dedicated to training and the 20% left is used as a test dataset.\n",
    "\n",
    "To ensure that we keep the same elements within the two datasets, even after restarting the notebook, we add add a train column to the annotation_dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"train\" not in annotations:\n",
    "\n",
    "    train_size = int(0.90*len(annotations)) # len(annotations) == len(FMD)\n",
    "    train_ids = rd.sample(range(len(annotations)), train_size)\n",
    "    annotations[\"train\"] = [i in train_ids for i in range(len(annotations))]\n",
    "    annotations.to_csv(anno_dir+\"annotations.csv\", index=None)\n",
    "\n",
    "train_dataset = FaceMaskDataset(annotations[annotations[\"train\"]], imgs_dir)\n",
    "test_dataset = FaceMaskDataset(annotations[annotations[\"train\"] == False], imgs_dir)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. THE MODELS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.1. DEFINING THE MODELS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRSN18 = models.resnet18(pretrained=True)\n",
    "for param in modelRSN18.parameters():\n",
    "    param.requires_grad = False\n",
    "modelRSN18.fc = nn.Sequential(\n",
    "    nn.Linear(512,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "modelRSN18.to(device)\n",
    "modelRSN18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRSN50 = models.resnet50(pretrained=True)\n",
    "for param in modelRSN50.parameters():\n",
    "    param.requires_grad = False\n",
    "modelRSN50.fc = nn.Sequential(\n",
    "    nn.Linear(2048,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "modelRSN50.to(device)\n",
    "modelRSN50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelVGG19 = models.vgg19(pretrained=True)\n",
    "# for param in modelVGG19.parameters():\n",
    "#     param.requires_grad = False\n",
    "# modelVGG19.fc = nn.Sequential(\n",
    "    # nn.Linear(2048,128),\n",
    "    # nn.ReLU(),\n",
    "    # nn.Linear(128,1),\n",
    "    # nn.Sigmoid())\n",
    "\n",
    "# modelVGG19.to(device)\n",
    "# modelVGG19.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.2. TRAINING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, nb_epochs, epoch_print_frequence):\n",
    "\n",
    "    s = time.time()\n",
    "\n",
    "    train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        running_loss_train, running_loss_test, running_acc_train, running_acc_test = 0,0,0,0\n",
    "\n",
    "        for train in [True, False]:\n",
    "\n",
    "            if train:\n",
    "                dataloader = train_dataloader\n",
    "                model.train()\n",
    "            else:\n",
    "                dataloader = test_dataloader\n",
    "                model.eval()\n",
    "\n",
    "            for inputs,labels in dataloader:\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                if train:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if train:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss_train += loss.item()\n",
    "                    running_acc_train += np.sum(labels.cpu().detach().numpy() == np.round(outputs.cpu().detach().numpy())) \n",
    "                    \n",
    "                else:\n",
    "                    running_loss_test += loss.item()\n",
    "                    running_acc_test += np.sum(labels.cpu().detach().numpy() == np.round(outputs.cpu().detach().numpy())) \n",
    "\n",
    "        running_loss_train /= len(train_dataset)\n",
    "        running_loss_test /= len(test_dataset)\n",
    "        running_acc_train /= len(train_dataset)\n",
    "        running_acc_test /= len(test_dataset)\n",
    "\n",
    "        train_losses.append(running_loss_train)\n",
    "        test_losses.append(running_loss_test)\n",
    "        train_accuracies.append(running_acc_train)\n",
    "        test_accuracies.append(running_acc_test)\n",
    "\n",
    "        if epoch % epoch_print_frequence == 0 and epoch > 0:\n",
    "            print(\"epochs {} ({} s) | train loss : {} | test loss : {} | train acc : {} | test acc : {}\".format(\n",
    "                epoch,\n",
    "                int(time.time()-s),\n",
    "                int(1000000*running_loss_train)/1000000,\n",
    "                int(1000000*running_loss_test)/1000000,\n",
    "                int(1000000*running_acc_train)/1000000,\n",
    "                int(1000000*running_acc_test)/1000000)\n",
    "            )\n",
    "    \n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerRSN18 = torch.optim.Adam(modelRSN18.parameters(), lr=1e-3)\n",
    "optimizerRSN50 = torch.optim.Adam(modelRSN50.parameters(), lr=1e-3)\n",
    "# optimizerVGG19 = torch.optim.Adam(modelVGG19.parameters(), lr=1e-3)\n",
    "\n",
    "criterionRSN18 = nn.CrossEntropyLoss().cuda()\n",
    "criterionRSN50 = nn.CrossEntropyLoss().cuda()\n",
    "# criterionVGG19 = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs, epoch_print_frequence = 50, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRSN18 = train_model(modelRSN18, criterionRSN18, optimizerRSN18, nb_epochs, epoch_print_frequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRSN50 = train_model(modelRSN50, criterionRSN50, optimizerRSN50, nb_epochs, epoch_print_frequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultsVGG19 = train_model(modelVGG19, criterionVGG19, optimizerVGG19, nb_epochs, epoch_print_frequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.3. SAVING THE MODEL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelRSN18.state_dict(), \"./models/MaskRecognitionRSN18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelRSN50.state_dict(), \"./models/MaskRecognitionRSN50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(modelVGG19.state_dict(), \"./models/MaskRecognitionVGG19.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. TESTING THE MODELS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3.1. LOADING THE MODELS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRSN18 = models.resnet18(pretrained=True)\n",
    "for param in modelRSN18.parameters():\n",
    "    param.requires_grad = False\n",
    "modelRSN18.fc = nn.Sequential(\n",
    "    nn.Linear(512,1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "modelRSN18.to(device)\n",
    "modelRSN18.load_state_dict(torch.load(\"./models/MaskRecognitionRSN18.pt\"))\n",
    "modelRSN18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRSN50 = models.resnet50(pretrained=True)\n",
    "for param in modelRSN50.parameters():\n",
    "    param.requires_grad = False\n",
    "modelRSN50.fc = nn.Sequential(\n",
    "    nn.Linear(2048,1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "modelRSN50.to(device)\n",
    "modelRSN50.load_state_dict(torch.load(\"./models/MaskRecognitionRSN50.pt\"))\n",
    "modelRSN50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelVGG19 = models.vgg19(pretrained=True)\n",
    "# for param in modelVGG19.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# modelVGG19.to(device)\n",
    "# modelVGG19.load_state_dict(torch.load(\"./models/MaskRecognitionVGG19.pt\"))\n",
    "# modelVGG19.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3.2. ACCURACIES*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(annotations[annotations[\"train\"]][\"label\"])\n",
    "test_labels = np.array(annotations[annotations[\"train\"] == False][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23258/1196252994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# test_labelsVGG19 = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/maksssksksss{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "train_labelsRSN18 = []\n",
    "train_labelsRSN50 = []\n",
    "# train_labelsVGG19 = []\n",
    "\n",
    "test_labelsRSN18 = []\n",
    "test_labelsRSN50 = []\n",
    "# test_labelsVGG19 = []\n",
    "\n",
    "for i in tqdm(range(len(annotations))):\n",
    "\n",
    "    img = plt.imread(imgs_dir+\"/maksssksksss{}.png\".format(annotations.iloc[i][\"img_id\"]))[:,:,:3]\n",
    "    xmin = annotations.iloc[i][\"xmin\"]\n",
    "    xmax = annotations.iloc[i][\"xmax\"]\n",
    "    ymin = annotations.iloc[i][\"ymin\"]\n",
    "    ymax = annotations.iloc[i][\"ymax\"]\n",
    "\n",
    "    label = annotations.iloc[i][\"label\"]\n",
    "\n",
    "    img_tensor = transforms.Resize((64,64))(torch.Tensor(img[ymin:ymax,xmin:xmax]).permute(2,0,1))\n",
    "    img_tensor = img_tensor.reshape((1,3,64,64)).to(device)\n",
    "\n",
    "    predRSN18 = torch.round(modelRSN18(img_tensor)).item()\n",
    "    predRSN50 = torch.round(modelRSN50(img_tensor)).item()\n",
    "    # predVGG19 = torch.round(modelVGG19(img_tensor)).item()\n",
    "\n",
    "    if annotations.iloc[i][\"train\"]:\n",
    "        train_labelsRSN18.append(predRSN18)\n",
    "        train_labelsRSN50.append(predRSN50)\n",
    "        # train_labelsVGG19.append(predVGG19)\n",
    "    else:\n",
    "        test_labelsRSN18.append(predRSN18)\n",
    "        test_labelsRSN50.append(predRSN50)\n",
    "        # test_labelsVGG19.append(predVGG19)\n",
    "\n",
    "train_labelsRSN18 = np.array(train_labelsRSN18)\n",
    "train_labelsRSN50 = np.array(train_labelsRSN50)\n",
    "# train_labelsVGG19 = np.array(train_labelsVGG19)\n",
    "\n",
    "test_labelsRSN18 = np.array(test_labelsRSN18)\n",
    "test_labelsRSN50 = np.array(test_labelsRSN50)\n",
    "# test_labelsVGG19 = np.array(test_labelsVGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cmRSN18 = confusion_matrix(train_labels, train_labelsRSN18)\n",
    "train_dispRSN18 = ConfusionMatrixDisplay(confusion_matrix=train_cmRSN18)\n",
    "train_dispRSN18.plot()\n",
    "plt.title(\"ResNet18 Confusion Matrix\\nOver the Train Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cmRSN18 = confusion_matrix(test_labels, test_labelsRSN18)\n",
    "test_dispRSN18 = ConfusionMatrixDisplay(confusion_matrix=test_cmRSN18)\n",
    "test_dispRSN18.plot()\n",
    "plt.title(\"ResNet18 Confusion Matrix\\nOver the Test Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_cmRSN50 = confusion_matrix(train_labels, train_labelsRSN50)\n",
    "train_dispRSN50 = ConfusionMatrixDisplay(confusion_matrix=train_cmRSN50)\n",
    "train_dispRSN50.plot()\n",
    "plt.title(\"ResNet50 Confusion Matrix\\nOver the Train Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_cmRSN50 = confusion_matrix(test_labels, test_labelsRSN50)\n",
    "test_dispRSN50 = ConfusionMatrixDisplay(confusion_matrix=test_cmRSN50)\n",
    "test_dispRSN50.plot()\n",
    "plt.title(\"ResNet50 Confusion Matrix\\nOver the Test Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cmVGG19 = confusion_matrix(train_labels, train_labelsVGG19)\n",
    "# train_dispVGG19 = ConfusionMatrixDisplay(confusion_matrix=train_cmVGG19)\n",
    "# train_dispVGG19.plot()\n",
    "# plt.title(\"VGGNet19 Confusion Matrix\\nOver the Train Dataset\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cmVGG19 = confusion_matrix(test_labels, test_labelsVGG19)\n",
    "# test_dispVGG19 = ConfusionMatrixDisplay(confusion_matrix=test_cmVGG19)\n",
    "# test_dispVGG19.plot()\n",
    "# plt.title(\"VGGNet19 Confusion Matrix\\nOver the Train Dataset\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3.3. VISUALIZING PREDICTION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_results(model, nb_images):\n",
    "\n",
    "    img_ids = rd.sample(list(annotations[\"img_id\"]), nb_images)\n",
    "\n",
    "    for img_id in img_ids:\n",
    "\n",
    "        a = annotations[annotations[\"img_id\"] == img_id]\n",
    "        img = plt.imread(imgs_dir+\"/maksssksksss{}.png\".format(img_id))[:,:,:3]\n",
    "        overlay = img.copy()\n",
    "        output = img.copy()\n",
    "\n",
    "        for i in range(len(a)):\n",
    "            \n",
    "            xmin = a.iloc[i][\"xmin\"]\n",
    "            xmax = a.iloc[i][\"xmax\"]\n",
    "            ymin = a.iloc[i][\"ymin\"]\n",
    "            ymax = a.iloc[i][\"ymax\"]\n",
    "            \n",
    "            img_tensor = transforms.Resize((64,64))(torch.Tensor(img[ymin:ymax,xmin:xmax]).permute(2,0,1))\n",
    "            img_tensor = img_tensor.reshape((1,3,64,64)).to(device)\n",
    "            pred = torch.round(model(img_tensor)).item()\n",
    "\n",
    "            if pred == 0:\n",
    "                cv2.rectangle(overlay, (xmin,ymin), (xmax,ymax), (2,0,0), -1)\n",
    "            \n",
    "            else:\n",
    "                cv2.rectangle(overlay, (xmin,ymin), (xmax,ymax), (0,1,0), -1)\n",
    "            \n",
    "            output = cv2.addWeighted(overlay, 0.05, output, 0.90, 0, output)\n",
    "                \n",
    "        plt.figure(figsize=(15,9))\n",
    "        plt.imshow(output)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_results(modelRSN50, 5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
